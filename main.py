"""
ë„ë§¤ê¾¹ ì‚¬ì´íŠ¸ ê²€ìƒ‰ ë„êµ¬ - ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""
import argparse
import json
import os
import sys
from typing import List, Optional
from urllib.parse import quote

from config import (
    RESULT_DIR, DEFAULT_MAX_RESULTS, DEFAULT_MIN_PRICE,
    get_username, get_password
)
from scraper import get_chrome_driver
from search import search_products
from parser import parse_search_results
from mybox import add_products_to_mybox
from logger import setup_logger, default_logger as logger
from trending import (
    get_trending_keywords, 
    get_keywords_from_result_files,
    get_trending_keywords_from_multiple_sources
)
from coupang_shopping import search_coupang_products
from naver_shopping import search_naver_shopping_products
from gmarket_shopping import search_gmarket_products
from st11_shopping import search_11st_products  # íŒŒì¼ëª…: 11st_shopping.py
from auction_shopping import search_auction_products
from interpark_shopping import search_interpark_products
from tmon_shopping import search_tmon_products
from wemakeprice_shopping import search_wemakeprice_products

def save_results(results: List[dict], keyword: str, output_format: str = 'json') -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        keyword: ê²€ìƒ‰ì–´
        output_format: ì¶œë ¥ í˜•ì‹ ('json', 'csv')
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(RESULT_DIR):
        os.makedirs(RESULT_DIR)
        logger.info(f"'{RESULT_DIR}' í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    
    # íŒŒì¼ëª… ìƒì„± (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
    safe_keyword = keyword.replace(' ', '_').replace('/', '_').replace('\\', '_')
    
    if output_format == 'json':
        output_file = os.path.join(RESULT_DIR, f"search_results_{safe_keyword}.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
    elif output_format == 'csv':
        import csv
        output_file = os.path.join(RESULT_DIR, f"search_results_{safe_keyword}.csv")
        if results:
            # ëª¨ë“  ê²°ê³¼ì—ì„œ ëª¨ë“  í•„ë“œëª… ìˆ˜ì§‘
            all_fieldnames = set()
            for result in results:
                all_fieldnames.update(result.keys())
            
            # í•„ë“œëª… ì •ë ¬ (search_keywordë¥¼ ë§¨ ì•ìœ¼ë¡œ)
            fieldnames = sorted(all_fieldnames)
            if 'search_keyword' in fieldnames:
                fieldnames.remove('search_keyword')
                fieldnames.insert(0, 'search_keyword')
            
            with open(output_file, 'w', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(results)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¶œë ¥ í˜•ì‹: {output_format}")
    
    logger.info(f"ê²°ê³¼ê°€ '{output_file}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return output_file

def print_results(results: List[dict], verbose: bool = False) -> None:
    """ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥"""
    if not results:
        logger.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"\nê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
    
    if verbose:
        for idx, product in enumerate(results, 1):
            print(f"\n[{idx}] {product.get('name', 'N/A')}")
            if product.get('product_id'):
                print(f"    ìƒí’ˆë²ˆí˜¸: {product['product_id']}")
            if product.get('price'):
                print(f"    ê°€ê²©: {product['price']}")
            if product.get('seller'):
                print(f"    íŒë§¤ì: {product['seller']}")
            if product.get('grade'):
                print(f"    ë“±ê¸‰: {product['grade']}ë“±ê¸‰")
            if product.get('fast_delivery'):
                print(f"    ë¹ ë¥¸ë°°ì†¡: ê°€ëŠ¥")
            if product.get('link'):
                print(f"    ë§í¬: {product['link']}")
    else:
        # ê°„ë‹¨í•œ ìš”ì•½ë§Œ ì¶œë ¥
        for idx, product in enumerate(results[:10], 1):  # ì²˜ìŒ 10ê°œë§Œ
            print(f"[{idx}] {product.get('name', 'N/A')} - {product.get('price', 'N/A')}")
        if len(results) > 10:
            print(f"... ì™¸ {len(results) - 10}ê°œ ë”")

def load_keywords_from_file(file_path: str) -> List[str]:
    """íŒŒì¼ì—ì„œ ê²€ìƒ‰ì–´ ëª©ë¡ ì½ê¸°"""
    keywords = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):  # ë¹ˆ ì¤„ê³¼ ì£¼ì„ ì œì™¸
                    keywords.append(line)
        logger.info(f"íŒŒì¼ì—ì„œ {len(keywords)}ê°œì˜ ê²€ìƒ‰ì–´ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤: {file_path}")
    except Exception as e:
        logger.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    return keywords

def extract_product_names_from_results_file(file_path: str, max_products: Optional[int] = None) -> List[str]:
    """
    ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼(CSV/JSON)ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ
    
    Args:
        file_path: ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (CSV ë˜ëŠ” JSON)
        max_products: ìµœëŒ€ ì¶”ì¶œí•  ìƒí’ˆ ìˆ˜ (Noneì´ë©´ ëª¨ë‘)
    
    Returns:
        ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸
    """
    product_names = []
    
    try:
        if file_path.endswith('.csv'):
            import csv
            with open(file_path, 'r', encoding='utf-8', newline='') as f:
                reader = csv.DictReader(f)
                for idx, row in enumerate(reader):
                    if max_products and idx >= max_products:
                        break
                    name = row.get('name', '').strip()
                    if name:
                        product_names.append(name)
        
        elif file_path.endswith('.json'):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    for idx, item in enumerate(data):
                        if max_products and idx >= max_products:
                            break
                        name = item.get('name', '').strip()
                        if name:
                            product_names.append(name)
                elif isinstance(data, dict):
                    name = data.get('name', '').strip()
                    if name:
                        product_names.append(name)
        
        logger.info(f"íŒŒì¼ì—ì„œ {len(product_names)}ê°œì˜ ìƒí’ˆëª…ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤: {file_path}")
        
    except Exception as e:
        logger.error(f"íŒŒì¼ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    return product_names

def register_products_from_results(
    results_file: str,
    max_products: Optional[int] = None,
    max_results_per_product: Optional[int] = None,
    min_price: Optional[int] = None,
    username: Optional[str] = None,
    password: Optional[str] = None,
    headless: bool = False
) -> bool:
    """
    ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì—ì„œ ìƒí’ˆëª…ì„ ì¶”ì¶œí•˜ì—¬ ë„ë§¤ê¾¹ì—ì„œ ê²€ìƒ‰í•˜ê³  ë§ˆì´ë°•ìŠ¤ì— ë“±ë¡
    
    Args:
        results_file: ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (CSV ë˜ëŠ” JSON)
        max_products: ìµœëŒ€ ì²˜ë¦¬í•  ìƒí’ˆ ìˆ˜ (Noneì´ë©´ ëª¨ë‘)
        max_results_per_product: ìƒí’ˆë‹¹ ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
        min_price: ìµœì†Œ ê°€ê²© í•„í„°
        username: ë¡œê·¸ì¸ ì•„ì´ë””
        password: ë¡œê·¸ì¸ ë¹„ë°€ë²ˆí˜¸
        headless: í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
    
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        logger.info("=" * 60)
        logger.info("ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì—ì„œ ìƒí’ˆ ë“±ë¡ ì‹œì‘")
        logger.info("=" * 60)
        
        # ìƒí’ˆëª… ì¶”ì¶œ
        product_names = extract_product_names_from_results_file(results_file, max_products)
        
        if not product_names:
            logger.error("ì¶”ì¶œëœ ìƒí’ˆëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        logger.info(f"ì´ {len(product_names)}ê°œì˜ ìƒí’ˆëª…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        # ë“œë¼ì´ë²„ ìƒì„± ë° ë¡œê·¸ì¸
        driver = get_chrome_driver(headless=headless)
        
        try:
            # ë¡œê·¸ì¸
            if username and password:
                from login import login_to_domeggook
                login_to_domeggook(driver, username=username, password=password)
            
            all_product_ids = []
            
            # ê° ìƒí’ˆëª…ìœ¼ë¡œ ë„ë§¤ê¾¹ì—ì„œ ê²€ìƒ‰
            for idx, product_name in enumerate(product_names, 1):
                logger.info("\n" + "=" * 60)
                logger.info(f"[{idx}/{len(product_names)}] ìƒí’ˆëª…: '{product_name}'")
                logger.info("=" * 60)
                
                try:
                    # ë„ë§¤ê¾¹ì—ì„œ ê²€ìƒ‰
                    search_result = search_products(
                        product_name,
                        headless=headless,
                        max_results=max_results_per_product or DEFAULT_MAX_RESULTS,
                        use_direct_url=True,
                        min_price=min_price,
                        username=username,
                        password=password,
                        return_driver=False,
                        driver=driver
                    )
                    
                    if search_result and isinstance(search_result, list):
                        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìƒí’ˆ ID ì¶”ì¶œ
                        product_ids = [p.get('product_id') for p in search_result if p.get('product_id')]
                        if product_ids:
                            all_product_ids.extend(product_ids)
                            logger.info(f"  âœ“ {len(product_ids)}ê°œ ìƒí’ˆ ë°œê²¬")
                        else:
                            logger.warning(f"  âš  ìƒí’ˆë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    else:
                        logger.warning(f"  âš  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                
                except Exception as e:
                    logger.error(f"  âœ— ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ëª¨ë“  ìƒí’ˆì„ ë§ˆì´ë°•ìŠ¤ì— ì¶”ê°€
            if all_product_ids:
                logger.info("\n" + "=" * 60)
                logger.info(f"ì´ {len(all_product_ids)}ê°œ ìƒí’ˆì„ ë§ˆì´ë°•ìŠ¤ì— ì¶”ê°€í•©ë‹ˆë‹¤")
                logger.info("=" * 60)
                
                # ì¤‘ë³µ ì œê±°
                unique_product_ids = list(dict.fromkeys(all_product_ids))
                logger.info(f"ì¤‘ë³µ ì œê±° í›„: {len(unique_product_ids)}ê°œ ìƒí’ˆ")
                
                # ë§ˆì´ë°•ìŠ¤ì— ì¶”ê°€
                success = add_products_to_mybox(driver, product_ids=unique_product_ids, select_all=False)
                
                if success:
                    logger.info("ìƒí’ˆ ë“±ë¡ ì™„ë£Œ!")
                    return True
                else:
                    logger.error("ìƒí’ˆ ë“±ë¡ ì‹¤íŒ¨")
                    return False
            else:
                logger.warning("ë“±ë¡í•  ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
        
        finally:
            driver.quit()
    
    except Exception as e:
        logger.error(f"ìƒí’ˆ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return False

def convert_json_to_csv(result_dir: str = RESULT_DIR, overwrite: bool = False) -> int:
    """
    result í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ì„ CSVë¡œ ë³€í™˜
    
    Args:
        result_dir: ê²°ê³¼ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        overwrite: ê¸°ì¡´ CSV íŒŒì¼ì´ ìˆìœ¼ë©´ ë®ì–´ì“¸ì§€ ì—¬ë¶€
    
    Returns:
        ë³€í™˜ëœ íŒŒì¼ ê°œìˆ˜
    """
    import csv
    import glob
    
    if not os.path.exists(result_dir):
        logger.warning(f"'{result_dir}' í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return 0
    
    # JSON íŒŒì¼ ì°¾ê¸°
    json_files = glob.glob(os.path.join(result_dir, "*.json"))
    
    if not json_files:
        logger.info(f"'{result_dir}' í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return 0
    
    logger.info(f"ì´ {len(json_files)}ê°œì˜ JSON íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    logger.info("=" * 60)
    
    converted_count = 0
    skipped_count = 0
    error_count = 0
    
    for json_file in json_files:
        try:
            # íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            base_name = os.path.basename(json_file)
            keyword = base_name.replace("search_results_", "").replace(".json", "")
            
            # CSV íŒŒì¼ ê²½ë¡œ
            csv_file = json_file.replace(".json", ".csv")
            
            # ì´ë¯¸ CSV íŒŒì¼ì´ ìˆê³  overwriteê°€ Falseë©´ ìŠ¤í‚µ
            if os.path.exists(csv_file) and not overwrite:
                logger.debug(f"  ìŠ¤í‚µ: {base_name} (CSV íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬)")
                skipped_count += 1
                continue
            
            # JSON íŒŒì¼ ì½ê¸°
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if not data:
                logger.debug(f"  ìŠ¤í‚µ: {base_name} (ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ)")
                skipped_count += 1
                continue
            
            # CSV íŒŒì¼ë¡œ ì €ì¥
            if isinstance(data, list) and len(data) > 0:
                fieldnames = data[0].keys()
                with open(csv_file, 'w', encoding='utf-8', newline='') as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(data)
                
                logger.info(f"  âœ“ ë³€í™˜ ì™„ë£Œ: {base_name} â†’ {len(data)}ê°œ ìƒí’ˆ")
                converted_count += 1
            else:
                logger.warning(f"  ê²½ê³ : {base_name} (ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° í˜•ì‹)")
                error_count += 1
                
        except json.JSONDecodeError as e:
            logger.error(f"  âœ— JSON íŒŒì‹± ì‹¤íŒ¨: {base_name} - {e}")
            error_count += 1
        except Exception as e:
            logger.error(f"  âœ— ë³€í™˜ ì‹¤íŒ¨: {base_name} - {e}")
            error_count += 1
    
    logger.info("=" * 60)
    logger.info(f"ë³€í™˜ ì™„ë£Œ!")
    logger.info(f"  - ì„±ê³µ: {converted_count}ê°œ")
    if skipped_count > 0:
        logger.info(f"  - ìŠ¤í‚µ: {skipped_count}ê°œ (ì´ë¯¸ CSV íŒŒì¼ ì¡´ì¬)")
    if error_count > 0:
        logger.info(f"  - ì‹¤íŒ¨: {error_count}ê°œ")
    
    return converted_count

def merge_csv_files(result_dir: str = RESULT_DIR, output_file: str = None, add_keyword_column: bool = True) -> str:
    """
    result í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ì„ í•˜ë‚˜ì˜ í†µí•© CSV íŒŒì¼ë¡œ ë³‘í•©
    
    Args:
        result_dir: ê²°ê³¼ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        add_keyword_column: ê²€ìƒ‰ì–´ ì»¬ëŸ¼ ì¶”ê°€ ì—¬ë¶€
    
    Returns:
        ìƒì„±ëœ í†µí•© CSV íŒŒì¼ ê²½ë¡œ
    """
    import csv
    import glob
    from datetime import datetime
    
    if not os.path.exists(result_dir):
        logger.warning(f"'{result_dir}' í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return ""
    
    # CSV íŒŒì¼ ì°¾ê¸°
    csv_files = glob.glob(os.path.join(result_dir, "search_results_*.csv"))
    
    if not csv_files:
        logger.warning(f"'{result_dir}' í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    
    logger.info(f"ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    logger.info("=" * 60)
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„± (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì €ì¥)
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬)
        project_root = os.path.dirname(os.path.abspath(__file__))
        output_file = os.path.join(project_root, f"merged_results_{timestamp}.csv")
    elif not os.path.isabs(output_file):
        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
        project_root = os.path.dirname(os.path.abspath(__file__))
        output_file = os.path.join(project_root, output_file)
    
    all_rows = []
    all_fieldnames = set()
    processed_count = 0
    total_rows = 0
    error_count = 0
    
    # ëª¨ë“  CSV íŒŒì¼ ì½ê¸°
    for csv_file in csv_files:
        try:
            # íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            base_name = os.path.basename(csv_file)
            keyword = base_name.replace("search_results_", "").replace(".csv", "")
            
            with open(csv_file, 'r', encoding='utf-8', newline='') as f:
                reader = csv.DictReader(f)
                
                # í•„ë“œëª… ìˆ˜ì§‘
                fieldnames = reader.fieldnames
                if fieldnames:
                    all_fieldnames.update(fieldnames)
                    
                    # ê° í–‰ ì½ê¸°
                    file_rows = 0
                    for row in reader:
                        # ê²€ìƒ‰ì–´ ì»¬ëŸ¼ ì¶”ê°€
                        if add_keyword_column:
                            row['search_keyword'] = keyword
                        all_rows.append(row)
                        file_rows += 1
                        total_rows += 1
                    
                    if file_rows > 0:
                        logger.info(f"  âœ“ ì²˜ë¦¬ ì™„ë£Œ: {base_name} â†’ {file_rows}ê°œ ìƒí’ˆ")
                        processed_count += 1
                    else:
                        logger.debug(f"  ìŠ¤í‚µ: {base_name} (ë°ì´í„° ì—†ìŒ)")
                else:
                    logger.warning(f"  ê²½ê³ : {base_name} (í—¤ë” ì—†ìŒ)")
                    error_count += 1
                    
        except Exception as e:
            logger.error(f"  âœ— ì½ê¸° ì‹¤íŒ¨: {base_name} - {e}")
            error_count += 1
    
    if not all_rows:
        logger.warning("ë³‘í•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    
    # ê²€ìƒ‰ì–´ ì»¬ëŸ¼ì„ í•„ë“œëª…ì— ì¶”ê°€
    if add_keyword_column and 'search_keyword' not in all_fieldnames:
        all_fieldnames.add('search_keyword')
    
    # í•„ë“œëª… ì •ë ¬ (search_keywordë¥¼ ë§¨ ì•ìœ¼ë¡œ)
    sorted_fieldnames = sorted(all_fieldnames)
    if 'search_keyword' in sorted_fieldnames:
        sorted_fieldnames.remove('search_keyword')
        sorted_fieldnames.insert(0, 'search_keyword')
    
    # í†µí•© CSV íŒŒì¼ë¡œ ì €ì¥
    try:
        with open(output_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=sorted_fieldnames)
            writer.writeheader()
            writer.writerows(all_rows)
        
        logger.info("=" * 60)
        logger.info(f"í†µí•© CSV íŒŒì¼ ìƒì„± ì™„ë£Œ!")
        logger.info(f"  - ì²˜ë¦¬ëœ íŒŒì¼: {processed_count}ê°œ")
        logger.info(f"  - ì´ ìƒí’ˆ ìˆ˜: {total_rows}ê°œ")
        logger.info(f"  - ì¶œë ¥ íŒŒì¼: {os.path.basename(output_file)}")
        if error_count > 0:
            logger.info(f"  - ì‹¤íŒ¨: {error_count}ê°œ")
        
        return output_file
        
    except Exception as e:
        logger.error(f"í†µí•© CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return ""

def parse_arguments():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description='ë„ë§¤ê¾¹ ì‚¬ì´íŠ¸ ìƒí’ˆ ê²€ìƒ‰ ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‚¬ìš© (ëŒ€í™”í˜• ëª¨ë“œ - ê²€ìƒ‰ì–´ ì…ë ¥ ìš”ì²­)
  python main.py
  
  # ë¹ ë¥¸ ê²€ìƒ‰ (ê²€ìƒ‰ì–´ë¥¼ ëª…ë ¹ì¤„ì—ì„œ ì§€ì •)
  python main.py --quick ì–‘ë§
  
  # ì—¬ëŸ¬ ê²€ìƒ‰ì–´ ë¹ ë¥¸ ê²€ìƒ‰
  python main.py -q ì–‘ë§ ì¥ê°‘ ëª¨ì
  
  # ì˜µì…˜ë§Œ ì§€ì •í•˜ê³  ê²€ìƒ‰ì–´ëŠ” ì…ë ¥ë°›ê¸°
  python main.py --max-results 10 --min-price 15000
  
  # íŒŒì¼ì—ì„œ ê²€ìƒ‰ì–´ ì½ê¸°
  python main.py --file keywords.txt
  
  # ë¹ ë¥¸ ê²€ìƒ‰ + ì˜µì…˜
  python main.py -q ì–‘ë§ --max-results 10 --min-price 15000
  
  # ë§ˆì´ë°•ìŠ¤ì— ì¶”ê°€í•˜ì§€ ì•Šê³  ê²€ìƒ‰ë§Œ
  python main.py --no-mybox
  
  # ìƒì„¸ ì¶œë ¥
  python main.py --verbose
  
  # CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥
  python main.py --format csv
  
  # result í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ì„ CSVë¡œ ë³€í™˜
  python main.py --convert-json-to-csv
  
  # CSV ë³€í™˜ ì‹œ ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°
  python main.py --convert-json-to-csv --overwrite-csv
  
  # result í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë³‘í•©
  python main.py --merge-csv
  
  # í†µí•© CSV íŒŒì¼ì˜ ì¶œë ¥ ê²½ë¡œ ì§€ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì €ì¥)
  python main.py --merge-csv --merge-output all_products.csv
  
  # ê²€ìƒ‰ì–´ ì»¬ëŸ¼ ì—†ì´ ë³‘í•©
  python main.py --merge-csv --no-keyword-column
  
  # ì¿ íŒ¡ ì‡¼í•‘ëª°ì—ì„œ ê²€ìƒ‰
  python main.py -q ì–‘ë§ --search-coupang
  
  # ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ ê²€ìƒ‰
  python main.py -q ì–‘ë§ --search-naver
  
  # ë„ë§¤ê¾¹, ì¿ íŒ¡, ë„¤ì´ë²„ ì‡¼í•‘ ëª¨ë‘ì—ì„œ ê²€ìƒ‰
  python main.py -q ì–‘ë§ --search-all
  
  # ëª¨ë“  ì§€ì› ì‚¬ì´íŠ¸ì—ì„œ ê²€ìƒ‰ (ë„ë§¤ê¾¹, ì¿ íŒ¡, ë„¤ì´ë²„, ì§€ë§ˆì¼“, 11ë²ˆê°€, ì˜¥ì…˜, ì¸í„°íŒŒí¬, í‹°ëª¬, ìœ„ë©”í”„)
  python main.py -q ì–‘ë§ --search-all-sites
  
  # íŠ¹ì • ì‚¬ì´íŠ¸ì—ì„œë§Œ ê²€ìƒ‰
  python main.py -q ì–‘ë§ --search-gmarket
  python main.py -q ì–‘ë§ --search-11st
  python main.py -q ì–‘ë§ --search-auction
  python main.py -q ì–‘ë§ --search-interpark
  python main.py -q ì–‘ë§ --search-tmon
  python main.py -q ì–‘ë§ --search-wemakeprice
  
  # ì¿ íŒ¡ì—ì„œ ê²€ìƒ‰ + ê°€ê²© í•„í„°
  python main.py -q ì–‘ë§ --search-coupang --min-price 10000 --max-price 50000
  
  # ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œí•˜ì—¬ ë„ë§¤ê¾¹ì—ì„œ ê²€ìƒ‰í•˜ê³  ë“±ë¡
  python main.py --register-from-file merged_results_20251117_154320.csv
  
  # í†µí•© CSV íŒŒì¼ì—ì„œ ìµœëŒ€ 100ê°œ ìƒí’ˆë§Œ ë“±ë¡
  python main.py --register-from-file merged_results_20251117_154320.csv --max-register-products 100
  
  # ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì—ì„œ ìƒí’ˆ ë“±ë¡ (ìƒí’ˆë‹¹ ìµœëŒ€ 5ê°œ ê²°ê³¼)
  python main.py --register-from-file result/search_results_ì–‘ë§.csv --max-results-per-product 5
        """
    )
    
    # ê²€ìƒ‰ì–´ ê´€ë ¨
    parser.add_argument(
        '-q', '--quick',
        nargs='+',
        metavar='KEYWORD',
        help='ë¹ ë¥¸ ê²€ìƒ‰ ëª¨ë“œ: ê²€ìƒ‰ì–´ë¥¼ ëª…ë ¹ì¤„ì—ì„œ ì§ì ‘ ì§€ì • (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)'
    )
    parser.add_argument(
        '-f', '--file',
        type=str,
        help='ê²€ìƒ‰ì–´ ëª©ë¡ì´ ìˆëŠ” íŒŒì¼ ê²½ë¡œ (í•œ ì¤„ì— í•˜ë‚˜ì”©)'
    )
    parser.add_argument(
        '--trending',
        action='store_true',
        help='ì¸ê¸° í‚¤ì›Œë“œë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ì—¬ ê²€ìƒ‰'
    )
    parser.add_argument(
        '--trending-count',
        type=int,
        default=50,
        help='ìˆ˜ì§‘í•  ì¸ê¸° í‚¤ì›Œë“œ ê°œìˆ˜ (ê¸°ë³¸ê°’: 50)'
    )
    parser.add_argument(
        '--multi-source',
        action='store_true',
        help='ì—¬ëŸ¬ ì†ŒìŠ¤ë¥¼ ë™ì‹œì— í™œìš©í•˜ì—¬ ë” ë§ì€ í‚¤ì›Œë“œ ìˆ˜ì§‘ (8ê°œ ì‚¬ì´íŠ¸: ë„¤ì´ë²„, ë„¤ì´ë²„ë°ì´í„°ë©, ì¿ íŒ¡, ì¿ íŒ¡íŠ¸ë Œë“œ, ì•„ì´í…œìŠ¤ì¹´ìš°íŠ¸, ì§€ë§ˆì¼“, 11ë²ˆê°€, êµ¬ê¸€íŠ¸ë Œë“œ)'
    )
    parser.add_argument(
        '--trending-source',
        choices=['auto', 'products', 'search_suggestions', 'categories', 'results', 
                 'naver', 'coupang', 'itemscout', 'gmarket', '11st', 'google'],
        default='auto',
        help='ì¸ê¸° í‚¤ì›Œë“œ ìˆ˜ì§‘ ì†ŒìŠ¤ (ê¸°ë³¸ê°’: auto) - naver: ë„¤ì´ë²„ ì‡¼í•‘, coupang: ì¿ íŒ¡, itemscout: ì•„ì´í…œ ìŠ¤ì¹´ìš°íŠ¸, gmarket: ì§€ë§ˆì¼“, 11st: 11ë²ˆê°€, google: êµ¬ê¸€ íŠ¸ë Œë“œ'
    )
    parser.add_argument(
        '--search-coupang',
        action='store_true',
        help='ì¿ íŒ¡ ì‡¼í•‘ëª°ì—ì„œ ìƒí’ˆ ê²€ìƒ‰ (ë„ë§¤ê¾¹ ëŒ€ì‹  ì¿ íŒ¡ì—ì„œ ê²€ìƒ‰)'
    )
    parser.add_argument(
        '--search-naver',
        action='store_true',
        help='ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ ìƒí’ˆ ê²€ìƒ‰ (ë„ë§¤ê¾¹ ëŒ€ì‹  ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ ê²€ìƒ‰)'
    )
    parser.add_argument(
        '--search-all',
        action='store_true',
        help='ë„ë§¤ê¾¹, ì¿ íŒ¡, ë„¤ì´ë²„ ì‡¼í•‘ì—ì„œ ëª¨ë‘ ê²€ìƒ‰'
    )
    parser.add_argument(
        '--search-gmarket',
        action='store_true',
        help='ì§€ë§ˆì¼“ì—ì„œ ìƒí’ˆ ê²€ìƒ‰'
    )
    parser.add_argument(
        '--search-11st',
        action='store_true',
        help='11ë²ˆê°€ì—ì„œ ìƒí’ˆ ê²€ìƒ‰'
    )
    parser.add_argument(
        '--search-auction',
        action='store_true',
        help='ì˜¥ì…˜ì—ì„œ ìƒí’ˆ ê²€ìƒ‰'
    )
    parser.add_argument(
        '--search-interpark',
        action='store_true',
        help='ì¸í„°íŒŒí¬ì—ì„œ ìƒí’ˆ ê²€ìƒ‰'
    )
    parser.add_argument(
        '--search-tmon',
        action='store_true',
        help='í‹°ëª¬ì—ì„œ ìƒí’ˆ ê²€ìƒ‰'
    )
    parser.add_argument(
        '--search-wemakeprice',
        action='store_true',
        help='ìœ„ë©”í”„ì—ì„œ ìƒí’ˆ ê²€ìƒ‰'
    )
    parser.add_argument(
        '--search-all-sites',
        action='store_true',
        help='ëª¨ë“  ì§€ì› ì‚¬ì´íŠ¸ì—ì„œ ê²€ìƒ‰ (ë„ë§¤ê¾¹, ì¿ íŒ¡, ë„¤ì´ë²„, ì§€ë§ˆì¼“, 11ë²ˆê°€, ì˜¥ì…˜, ì¸í„°íŒŒí¬, í‹°ëª¬, ìœ„ë©”í”„)'
    )
    parser.add_argument(
        '--max-price',
        type=int,
        help='ìµœëŒ€ ê°€ê²© í•„í„°'
    )
    parser.add_argument(
        '--exclude-brands',
        action='store_true',
        help='ë¸Œëœë“œ í‚¤ì›Œë“œ ì œì™¸ (ì¼ë°˜ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ)'
    )
    parser.add_argument(
        '--analyze-competition',
        action='store_true',
        help='ê²½ìŸ ë¶„ì„ ë°ì´í„° í¬í•¨ (ê²€ìƒ‰ìˆ˜, ìƒí’ˆìˆ˜, ê²½ìŸê°•ë„ ë“±)'
    )
    
    # ê²€ìƒ‰ ì˜µì…˜
    parser.add_argument(
        '--max-results',
        type=int,
        default=DEFAULT_MAX_RESULTS,
        help=f'ê°€ì ¸ì˜¬ ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: {DEFAULT_MAX_RESULTS})'
    )
    parser.add_argument(
        '--pages',
        type=int,
        default=1,
        help='ê°€ì ¸ì˜¬ ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’: 1, ì—¬ëŸ¬ í˜ì´ì§€ ê²€ìƒ‰ ì‹œ ì‚¬ìš©)'
    )
    parser.add_argument(
        '--min-price',
        type=int,
        default=DEFAULT_MIN_PRICE,
        help=f'ìµœì†Œ ê°€ê²© í•„í„° (ê¸°ë³¸ê°’: {DEFAULT_MIN_PRICE:,}ì›)'
    )
    parser.add_argument(
        '--no-price-filter',
        action='store_true',
        help='ê°€ê²© í•„í„°ë§ ë¹„í™œì„±í™”'
    )
    
    # ì‹¤í–‰ ì˜µì…˜
    parser.add_argument(
        '--headless',
        action='store_true',
        default=False,
        help='í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (ë¸Œë¼ìš°ì € ì°½ ìˆ¨ê¹€)'
    )
    parser.add_argument(
        '--no-mybox',
        action='store_true',
        help='ë§ˆì´ë°•ìŠ¤ì— ì¶”ê°€í•˜ì§€ ì•Šê³  ê²€ìƒ‰ë§Œ ìˆ˜í–‰'
    )
    parser.add_argument(
        '--use-form',
        action='store_true',
        help='ê²€ìƒ‰ í¼ ì‚¬ìš© ë°©ì‹ (ê¸°ë³¸ê°’: ì§ì ‘ URL ì ‘ê·¼)'
    )
    
    # ì¶œë ¥ ì˜µì…˜
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='ìƒì„¸ ì¶œë ¥'
    )
    parser.add_argument(
        '--format',
        choices=['json', 'csv'],
        default='json',
        help='ê²°ê³¼ ì €ì¥ í˜•ì‹ (ê¸°ë³¸ê°’: json)'
    )
    parser.add_argument(
        '--no-save',
        action='store_true',
        help='ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•ŠìŒ'
    )
    parser.add_argument(
        '--convert-json-to-csv',
        action='store_true',
        help='result í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ì„ CSVë¡œ ë³€í™˜'
    )
    parser.add_argument(
        '--overwrite-csv',
        action='store_true',
        help='CSV ë³€í™˜ ì‹œ ê¸°ì¡´ CSV íŒŒì¼ ë®ì–´ì“°ê¸° (--convert-json-to-csvì™€ í•¨ê»˜ ì‚¬ìš©)'
    )
    parser.add_argument(
        '--merge-csv',
        action='store_true',
        help='result í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ì„ í•˜ë‚˜ì˜ í†µí•© CSV íŒŒì¼ë¡œ ë³‘í•©'
    )
    parser.add_argument(
        '--merge-output',
        type=str,
        help='í†µí•© CSV íŒŒì¼ì˜ ì¶œë ¥ ê²½ë¡œ (--merge-csvì™€ í•¨ê»˜ ì‚¬ìš©, ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ìƒì„±)'
    )
    parser.add_argument(
        '--no-keyword-column',
        action='store_true',
        help='í†µí•© CSVì— ê²€ìƒ‰ì–´ ì»¬ëŸ¼ ì¶”ê°€í•˜ì§€ ì•Šê¸° (--merge-csvì™€ í•¨ê»˜ ì‚¬ìš©)'
    )
    parser.add_argument(
        '--register-from-file',
        type=str,
        help='ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼(CSV/JSON)ì—ì„œ ìƒí’ˆëª…ì„ ì¶”ì¶œí•˜ì—¬ ë„ë§¤ê¾¹ì—ì„œ ê²€ìƒ‰í•˜ê³  ë§ˆì´ë°•ìŠ¤ì— ë“±ë¡'
    )
    parser.add_argument(
        '--max-register-products',
        type=int,
        help='ë“±ë¡í•  ìµœëŒ€ ìƒí’ˆ ìˆ˜ (--register-from-fileê³¼ í•¨ê»˜ ì‚¬ìš©)'
    )
    parser.add_argument(
        '--max-results-per-product',
        type=int,
        help='ìƒí’ˆë‹¹ ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (--register-from-fileê³¼ í•¨ê»˜ ì‚¬ìš©)'
    )
    
    # ë¡œê·¸ì¸ ì˜µì…˜
    parser.add_argument(
        '--username',
        type=str,
        help='ë¡œê·¸ì¸ ì•„ì´ë”” (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ DOMEID ë˜ëŠ” ì…ë ¥ ìš”ì²­)'
    )
    parser.add_argument(
        '--password',
        type=str,
        help='ë¡œê·¸ì¸ ë¹„ë°€ë²ˆí˜¸ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ DOMPWD ë˜ëŠ” ì…ë ¥ ìš”ì²­)'
    )
    
    # ë¡œê¹… ì˜µì…˜
    parser.add_argument(
        '--log-level',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='ë¡œê·¸ ë ˆë²¨ (ê¸°ë³¸ê°’: INFO)'
    )
    parser.add_argument(
        '--log-file',
        type=str,
        help='ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ íŒŒì¼ ì €ì¥ ì•ˆ í•¨)'
    )
    
    return parser.parse_args()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    args = parse_arguments()
    
    # ë¡œê±° ì„¤ì •
    log_level = getattr(__import__('logging'), args.log_level)
    setup_logger(level=log_level, log_file=args.log_file)
    
    # JSON to CSV ë³€í™˜ ëª¨ë“œ
    if args.convert_json_to_csv:
        logger.info("=" * 60)
        logger.info("JSON â†’ CSV ë³€í™˜ ëª¨ë“œ")
        logger.info("=" * 60)
        converted = convert_json_to_csv(result_dir=RESULT_DIR, overwrite=args.overwrite_csv)
        logger.info(f"\nì´ {converted}ê°œì˜ íŒŒì¼ì´ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    
    # CSV ë³‘í•© ëª¨ë“œ
    if args.merge_csv:
        logger.info("=" * 60)
        logger.info("CSV íŒŒì¼ ë³‘í•© ëª¨ë“œ")
        logger.info("=" * 60)
        output_file = merge_csv_files(
            result_dir=RESULT_DIR,
            output_file=args.merge_output,
            add_keyword_column=not args.no_keyword_column
        )
        if output_file:
            logger.info(f"\ní†µí•© íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
        sys.exit(0)
    
    # ìƒí’ˆ ë“±ë¡ ëª¨ë“œ (ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œí•˜ì—¬ ë“±ë¡)
    if args.register_from_file:
        logger.info("=" * 60)
        logger.info("ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ì—ì„œ ìƒí’ˆ ë“±ë¡ ëª¨ë“œ")
        logger.info("=" * 60)
        
        # íŒŒì¼ ê²½ë¡œ í™•ì¸
        results_file = args.register_from_file
        if not os.path.isabs(results_file):
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
            project_root = os.path.dirname(os.path.abspath(__file__))
            results_file = os.path.join(project_root, results_file)
        
        if not os.path.exists(results_file):
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_file}")
            sys.exit(1)
        
        # ë¡œê·¸ì¸ ì •ë³´
        username = args.username or get_username()
        password = args.password or get_password()
        
        # ê°€ê²© í•„í„° ì„¤ì •
        min_price = None if args.no_price_filter else args.min_price
        
        # ìƒí’ˆ ë“±ë¡ ì‹¤í–‰
        success = register_products_from_results(
            results_file=results_file,
            max_products=args.max_register_products,
            max_results_per_product=args.max_results_per_product or args.max_results,
            min_price=min_price,
            username=username,
            password=password,
            headless=args.headless
        )
        
        if success:
            logger.info("\nìƒí’ˆ ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            logger.error("\nìƒí’ˆ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        sys.exit(0)
    
    # ê²€ìƒ‰ì–´ ìˆ˜ì§‘
    keywords = []
    
    # ìš°ì„ ìˆœìœ„: --quick > --file > --trending > ëŒ€í™”í˜• ëª¨ë“œ
    if args.quick:
        # ë¹ ë¥¸ ê²€ìƒ‰ ëª¨ë“œ: ëª…ë ¹ì¤„ì—ì„œ ê²€ìƒ‰ì–´ ì§€ì •
        keywords.extend(args.quick)
        logger.info(f"ë¹ ë¥¸ ê²€ìƒ‰ ëª¨ë“œ: {len(keywords)}ê°œì˜ ê²€ìƒ‰ì–´ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    elif args.file:
        # íŒŒì¼ì—ì„œ ê²€ìƒ‰ì–´ ì½ê¸°
        keywords.extend(load_keywords_from_file(args.file))
    elif args.trending:
        # ì¸ê¸° í‚¤ì›Œë“œ ìë™ ìˆ˜ì§‘ ëª¨ë“œ
        logger.info("=" * 60)
        logger.info("ì¸ê¸° í‚¤ì›Œë“œ ìë™ ìˆ˜ì§‘ ëª¨ë“œ")
        logger.info("=" * 60)
        
        # driver ìƒì„± (ì¸ê¸° í‚¤ì›Œë“œ ìˆ˜ì§‘ìš©)
        driver = get_chrome_driver(headless=args.headless)
        try:
            # ë¡œê·¸ì¸ (í•„ìš”í•œ ê²½ìš°)
            username = args.username or get_username()
            password = args.password or get_password()
            
            if username and password:
                from login import login_to_domeggook
                login_to_domeggook(driver, username=username, password=password)
            
            # ì¸ê¸° í‚¤ì›Œë“œ ìˆ˜ì§‘
            if args.trending_source == 'results':
                # ê³¼ê±° ê²°ê³¼ íŒŒì¼ì—ì„œ ì¶”ì¶œ
                keywords = get_keywords_from_result_files(
                    result_dir=RESULT_DIR,
                    max_keywords=args.trending_count
                )
                logger.info(f"ê³¼ê±° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ {len(keywords)}ê°œ í‚¤ì›Œë“œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            elif args.multi_source:
                # ì—¬ëŸ¬ ì†ŒìŠ¤ë¥¼ ë™ì‹œì— í™œìš©í•˜ì—¬ ìˆ˜ì§‘
                logger.info("ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ í‚¤ì›Œë“œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
                keywords = get_trending_keywords_from_multiple_sources(
                    driver=driver,
                    max_keywords=args.trending_count,
                    exclude_brands=args.exclude_brands,
                    analyze_competition_data=args.analyze_competition
                )
                logger.info(f"ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì´ {len(keywords)}ê°œ ì¸ê¸° í‚¤ì›Œë“œë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            else:
                # ì›¹ì—ì„œ ìˆ˜ì§‘
                keywords = get_trending_keywords(
                    driver=driver,
                    method=args.trending_source,
                    max_keywords=args.trending_count,
                    source=args.trending_source,
                    exclude_brands=args.exclude_brands,
                    analyze_competition_data=args.analyze_competition
                )
                logger.info(f"ì›¹ì—ì„œ {len(keywords)}ê°œ ì¸ê¸° í‚¤ì›Œë“œë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
                
                # ë¸Œëœë“œ ì œì™¸ ì˜µì…˜ì´ ìˆìœ¼ë©´ ì¶”ê°€ ì •ë³´ ì¶œë ¥
                if args.exclude_brands:
                    from brand_filter import is_brand_keyword
                    brand_count = sum(1 for kw in keywords if is_brand_keyword(kw))
                    logger.info(f"ë¸Œëœë“œ í‚¤ì›Œë“œ: {brand_count}ê°œ, ì¼ë°˜ í‚¤ì›Œë“œ: {len(keywords) - brand_count}ê°œ")
            
            if not keywords:
                logger.warning("ì¸ê¸° í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                keywords = ['ì–‘ë§', 'ì¥ê°‘', 'ëª¨ì']
            
            # í‚¤ì›Œë“œ ì¶œë ¥
            logger.info("\nìˆ˜ì§‘ëœ ì¸ê¸° í‚¤ì›Œë“œ:")
            for idx, kw in enumerate(keywords, 1):
                logger.info(f"  {idx}. {kw}")
            logger.info("")
            
        finally:
            # ì¸ê¸° í‚¤ì›Œë“œ ìˆ˜ì§‘ í›„ driverëŠ” ì¬ì‚¬ìš©í•˜ì§€ ì•Šê³  ì¢…ë£Œ
            driver.quit()
            driver = None
        
        if not keywords:
            logger.error("ì¸ê¸° í‚¤ì›Œë“œ ìˆ˜ì§‘ ì‹¤íŒ¨")
            sys.exit(1)
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ (ê¸°ë³¸ ë™ì‘)
        logger.info("=" * 60)
        logger.info("ë„ë§¤ê¾¹ ìƒí’ˆ ê²€ìƒ‰ ë„êµ¬ - ëŒ€í™”í˜• ëª¨ë“œ")
        logger.info("=" * 60)
        logger.info("\nê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„):")
        logger.info("ì˜ˆì‹œ: ì–‘ë§, ì¥ê°‘, ëª¨ì")
        logger.info("ë˜ëŠ”: ì–‘ë§")
        logger.info("")
        
        user_input = input("ê²€ìƒ‰ì–´: ").strip()
        
        if not user_input:
            logger.warning("ê²€ìƒ‰ì–´ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 'ì–‘ë§'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            keywords = ['ì–‘ë§']
        elif ',' in user_input:
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ ê²€ìƒ‰ì–´
            keywords = [kw.strip() for kw in user_input.split(',') if kw.strip()]
        else:
            # ë‹¨ì¼ ê²€ìƒ‰ì–´
            keywords = [user_input]
    
    if not keywords:
        logger.error("ê²€ìƒ‰ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    logger.info(f"\nì´ {len(keywords)}ê°œì˜ ê²€ìƒ‰ì–´ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤:")
    for idx, kw in enumerate(keywords, 1):
        logger.info(f"  {idx}. {kw}")
    
    # ê°€ê²© í•„í„° ì„¤ì •
    min_price = None if args.no_price_filter else args.min_price
    max_price = args.max_price
    
    # ë¡œê·¸ì¸ ì •ë³´
    username = args.username or get_username()
    password = args.password or get_password()
    
    # ê²€ìƒ‰ ì†ŒìŠ¤ ê²°ì •
    search_sources = []
    if args.search_all_sites:
        # ëª¨ë“  ì§€ì› ì‚¬ì´íŠ¸ì—ì„œ ê²€ìƒ‰
        search_sources = ['domeggook', 'coupang', 'naver', 'gmarket', '11st', 'auction', 'interpark', 'tmon', 'wemakeprice']
    elif args.search_all:
        search_sources = ['domeggook', 'coupang', 'naver']
    elif args.search_coupang:
        search_sources = ['coupang']
    elif args.search_naver:
        search_sources = ['naver']
    elif args.search_gmarket:
        search_sources = ['gmarket']
    elif args.search_11st:
        search_sources = ['11st']
    elif args.search_auction:
        search_sources = ['auction']
    elif args.search_interpark:
        search_sources = ['interpark']
    elif args.search_tmon:
        search_sources = ['tmon']
    elif args.search_wemakeprice:
        search_sources = ['wemakeprice']
    else:
        search_sources = ['domeggook']  # ê¸°ë³¸ê°’
    
    # driverëŠ” í•œ ë²ˆë§Œ ìƒì„±í•˜ê³  ì¬ì‚¬ìš©
    driver = None
    
    try:
        # ê° ê²€ìƒ‰ì–´ë§ˆë‹¤ ìˆœì°¨ ì²˜ë¦¬
        for search_idx, search_keyword in enumerate(keywords, 1):
            logger.info("\n" + "=" * 60)
            logger.info(f"[{search_idx}/{len(keywords)}] ê²€ìƒ‰ì–´: '{search_keyword}'")
            logger.info("=" * 60)
            
            all_results = []
            
            # ê° ê²€ìƒ‰ ì†ŒìŠ¤ì—ì„œ ê²€ìƒ‰
            for source in search_sources:
                logger.info(f"\n[{source.upper()}] ê²€ìƒ‰ ì¤‘...")
                
                if source == 'domeggook':
                    # ë„ë§¤ê¾¹ ê²€ìƒ‰
                    if driver is None:
                        search_result = search_products(
                            search_keyword,
                            headless=args.headless,
                            max_results=args.max_results,
                            use_direct_url=not args.use_form,
                            min_price=min_price,
                            username=username,
                            password=password,
                            return_driver=True,
                            max_pages=args.pages
                        )
                        
                        # ê²°ê³¼ì™€ driver ë¶„ë¦¬
                        if isinstance(search_result, tuple):
                            results, driver = search_result
                        else:
                            results = search_result
                            driver = None
                    else:
                        # ë‘ ë²ˆì§¸ ê²€ìƒ‰ì–´ë¶€í„°ëŠ” ê¸°ì¡´ driver ì¬ì‚¬ìš©
                        from urllib.parse import quote
                        from selenium.webdriver.common.by import By
                        from selenium.webdriver.support.ui import WebDriverWait
                        from selenium.webdriver.support import expected_conditions as EC
                        import time
                        
                        from config import SEARCH_URL_TEMPLATE
                        
                        encoded_keyword = quote(search_keyword, safe='')
                        search_url = SEARCH_URL_TEMPLATE.format(keyword=encoded_keyword)
                        driver.get(search_url)
                        logger.info(f"ê²€ìƒ‰ URLë¡œ ì´ë™: {search_url}")
                        
                        WebDriverWait(driver, 10).until(
                            EC.presence_of_element_located((By.TAG_NAME, "body"))
                        )
                        time.sleep(2)
                        
                        results = parse_search_results(driver, max_results=args.max_results, min_price=min_price)
                    
                    if results:
                        all_results.extend(results)
                        logger.info(f"  âœ“ ë„ë§¤ê¾¹: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                
                elif source == 'coupang':
                    # ì¿ íŒ¡ ì‡¼í•‘ëª° ê²€ìƒ‰ (undetected-chromedriver ì‚¬ìš©)
                    coupang_driver = None
                    try:
                        from coupang_shopping import search_coupang_products
                        results = search_coupang_products(
                            driver=None,  # ì¿ íŒ¡ ì „ìš© ë“œë¼ì´ë²„ ìë™ ìƒì„±
                            keyword=search_keyword,
                            max_results=args.max_results,
                            min_price=min_price,
                            max_price=max_price,
                            headless=args.headless
                        )
                        if results:
                            all_results.extend(results)
                            logger.info(f"  âœ“ ì¿ íŒ¡: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                        else:
                            logger.warning(f"  âš  ì¿ íŒ¡: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                    except ImportError as e:
                        logger.error(f"  âœ— ì¿ íŒ¡ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                        logger.info(f"  ğŸ’¡ 'pip install undetected-chromedriver' ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                    except Exception as e:
                        logger.error(f"  âœ— ì¿ íŒ¡ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                        logger.info(f"  ğŸ’¡ ë„¤ì´ë²„ ì‡¼í•‘(--search-naver) ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
                    finally:
                        # ì¿ íŒ¡ ë“œë¼ì´ë²„ëŠ” ë³„ë„ë¡œ ê´€ë¦¬ (undetected-chromedriverëŠ” ìë™ ì¢…ë£Œë¨)
                        pass
                
                elif source == 'naver':
                    # ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰
                    if driver is None:
                        driver = get_chrome_driver(headless=args.headless)
                    
                    try:
                        results = search_naver_shopping_products(
                            driver=driver,
                            keyword=search_keyword,
                            max_results=args.max_results,
                            min_price=min_price,
                            max_price=max_price
                        )
                        if results:
                            all_results.extend(results)
                            logger.info(f"  âœ“ ë„¤ì´ë²„ ì‡¼í•‘: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                    except Exception as e:
                        logger.error(f"  âœ— ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
                elif source == 'gmarket':
                    # ì§€ë§ˆì¼“ ê²€ìƒ‰
                    if driver is None:
                        driver = get_chrome_driver(headless=args.headless)
                    
                    try:
                        results = search_gmarket_products(
                            driver=driver,
                            keyword=search_keyword,
                            max_results=args.max_results,
                            min_price=min_price,
                            max_price=max_price,
                            headless=args.headless
                        )
                        if results:
                            all_results.extend(results)
                            logger.info(f"  âœ“ ì§€ë§ˆì¼“: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                    except Exception as e:
                        logger.error(f"  âœ— ì§€ë§ˆì¼“ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
                elif source == '11st':
                    # 11ë²ˆê°€ ê²€ìƒ‰
                    if driver is None:
                        driver = get_chrome_driver(headless=args.headless)
                    
                    try:
                        results = search_11st_products(
                            driver=driver,
                            keyword=search_keyword,
                            max_results=args.max_results,
                            min_price=min_price,
                            max_price=max_price,
                            headless=args.headless
                        )
                        if results:
                            all_results.extend(results)
                            logger.info(f"  âœ“ 11ë²ˆê°€: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                    except Exception as e:
                        logger.error(f"  âœ— 11ë²ˆê°€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
                elif source == 'auction':
                    # ì˜¥ì…˜ ê²€ìƒ‰
                    if driver is None:
                        driver = get_chrome_driver(headless=args.headless)
                    
                    try:
                        results = search_auction_products(
                            driver=driver,
                            keyword=search_keyword,
                            max_results=args.max_results,
                            min_price=min_price,
                            max_price=max_price,
                            headless=args.headless
                        )
                        if results:
                            all_results.extend(results)
                            logger.info(f"  âœ“ ì˜¥ì…˜: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                    except Exception as e:
                        logger.error(f"  âœ— ì˜¥ì…˜ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
                elif source == 'interpark':
                    # ì¸í„°íŒŒí¬ ê²€ìƒ‰
                    if driver is None:
                        driver = get_chrome_driver(headless=args.headless)
                    
                    try:
                        results = search_interpark_products(
                            driver=driver,
                            keyword=search_keyword,
                            max_results=args.max_results,
                            min_price=min_price,
                            max_price=max_price,
                            headless=args.headless
                        )
                        if results:
                            all_results.extend(results)
                            logger.info(f"  âœ“ ì¸í„°íŒŒí¬: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                    except Exception as e:
                        logger.error(f"  âœ— ì¸í„°íŒŒí¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
                elif source == 'tmon':
                    # í‹°ëª¬ ê²€ìƒ‰
                    if driver is None:
                        driver = get_chrome_driver(headless=args.headless)
                    
                    try:
                        results = search_tmon_products(
                            driver=driver,
                            keyword=search_keyword,
                            max_results=args.max_results,
                            min_price=min_price,
                            max_price=max_price,
                            headless=args.headless
                        )
                        if results:
                            all_results.extend(results)
                            logger.info(f"  âœ“ í‹°ëª¬: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                    except Exception as e:
                        logger.error(f"  âœ— í‹°ëª¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
                elif source == 'wemakeprice':
                    # ìœ„ë©”í”„ ê²€ìƒ‰
                    if driver is None:
                        driver = get_chrome_driver(headless=args.headless)
                    
                    try:
                        results = search_wemakeprice_products(
                            driver=driver,
                            keyword=search_keyword,
                            max_results=args.max_results,
                            min_price=min_price,
                            max_price=max_price,
                            headless=args.headless
                        )
                        if results:
                            all_results.extend(results)
                            logger.info(f"  âœ“ ìœ„ë©”í”„: {len(results)}ê°œ ìƒí’ˆ ë°œê²¬")
                    except Exception as e:
                        logger.error(f"  âœ— ìœ„ë©”í”„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            
            # í†µí•© ê²°ê³¼ ì‚¬ìš©
            results = all_results
            
            # ê²°ê³¼ ì¶œë ¥
            if results:
                print_results(results, verbose=args.verbose)
                
                # ê²°ê³¼ ì €ì¥
                if not args.no_save:
                    save_results(results, search_keyword, output_format=args.format)
                
                # ë§ˆì´ë°•ìŠ¤ì— ìƒí’ˆ ì¶”ê°€ (ì˜µì…˜) - ë„ë§¤ê¾¹ì—ì„œë§Œ ê°€ëŠ¥
                if driver and not args.no_mybox and 'domeggook' in search_sources:
                    # ë„ë§¤ê¾¹ ìƒí’ˆë§Œ í•„í„°ë§ (ë‹¤ë¥¸ ì‚¬ì´íŠ¸ ì œì™¸)
                    other_sources = ['coupang', 'naver_shopping', 'gmarket', '11st', 'auction', 'interpark', 'tmon', 'wemakeprice']
                    domeggook_results = [p for p in results if p.get('source') not in other_sources]
                    product_ids = [p.get('product_id') for p in domeggook_results if p.get('product_id')]
                    
                    if product_ids:
                        logger.info("\n" + "=" * 60)
                        logger.info(f"ë§ˆì´ë°•ìŠ¤ì— {len(product_ids)}ê°œ ìƒí’ˆ ì¶”ê°€ ë° ìŠ¤í”¼ë“œê³  ì „ì†¡ ì‹œë„")
                        logger.info("=" * 60)
                        
                        success = add_products_to_mybox(driver, product_ids=product_ids, select_all=False)
                        
                        if success:
                            logger.info(f"ê²€ìƒ‰ì–´ '{search_keyword}' ì²˜ë¦¬ ì™„ë£Œ!")
                        else:
                            logger.warning(f"ê²€ìƒ‰ì–´ '{search_keyword}' ì²˜ë¦¬ ì‹¤íŒ¨")
                    else:
                        logger.warning(f"ê²€ìƒ‰ì–´ '{search_keyword}': ìƒí’ˆë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë§ˆì´ë°•ìŠ¤ë‹´ê¸°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            else:
                logger.info(f"ê²€ìƒ‰ì–´ '{search_keyword}': ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë‹¤ìŒ ê²€ìƒ‰ì–´ ì²˜ë¦¬ ì „ ì ì‹œ ëŒ€ê¸°
            if search_idx < len(keywords):
                logger.info("\në‹¤ìŒ ê²€ìƒ‰ì–´ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                import time
                time.sleep(2)
    
    finally:
        # driver ì¢…ë£Œ
        if driver:
            logger.info("\në¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤...")
            driver.quit()
    
    logger.info("\n" + "=" * 60)
    logger.info("ëª¨ë“  ê²€ìƒ‰ì–´ ì²˜ë¦¬ ì™„ë£Œ!")
    logger.info("=" * 60)

if __name__ == "__main__":
    main()
